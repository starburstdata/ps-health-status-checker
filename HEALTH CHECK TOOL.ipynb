{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c25eb7",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84bd019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username: ········\n",
      "password: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import subprocess\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "        \n",
    "input_file='/Users/satya.dixit/Documents/Tools/HealthCheckerTool/input_health_check_configs.json'\n",
    "hostname='https://sbe-official-demo-warp-speed.fieldeng.starburstdata.net'\n",
    "port='443'\n",
    "role='sysadmin'\n",
    "username = getpass.getpass(prompt='username: ')\n",
    "password = getpass.getpass(prompt='password: ')\n",
    "catalog='query_logger'\n",
    "schema='public'\n",
    "# change duration below, default 3 months\n",
    "days=90        \n",
    "\n",
    "# If either username or password are missing, exit the script without proceeding further\n",
    "if username.strip() == '' or password.strip() == '':\n",
    "    print(\"username / password cannot be empty. Please try again.\")\n",
    "    exit()\n",
    "    \n",
    "current_date = datetime.now()\n",
    "analysis_start_date = (current_date - timedelta(days)).strftime(\"%Y-%m-%d\")\n",
    "analysis_end_date = current_date.strftime(\"%Y-%m-%d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f666e",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfc0a4",
   "metadata": {},
   "source": [
    "This paragraph will process the input json file and execute the sql queries in trino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b6a233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing the query for KPI -  hourly_cpu_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  daily_cpu_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  hourly_memory_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  daily_memory_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  hourly_node_count ..\n",
      "Done.\n",
      "Executing the query for KPI -  minutely_cpu_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  minutely_memory_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  minutely_node_count ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_trends ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_failure_rate ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_failure_rate_by_query_type ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_failure_by_query_type ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_failure_by_error_type ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_failure_by_error_type_and_name ..\n",
      "Done.\n",
      "Executing the query for KPI -  queries_per_minute ..\n",
      "Done.\n",
      "Executing the query for KPI -  data_processed ..\n",
      "Done.\n",
      "Executing the query for KPI -  query_perf_and_time_metrics ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_execution_time ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_planning_time ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_queued_time ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_scheduled_time ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_analysis_time ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_cpu_time ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_data_scanned ..\n",
      "Done.\n",
      "Executing the query for KPI -  top_x_splits_completed ..\n",
      "Done.\n",
      "Executing the query for KPI -  sample_errors ..\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#Main code 2 with pagination\n",
    "#cell2\n",
    "#!/usr/bin/env python3\n",
    "# coding: utf-8\n",
    "import trino\n",
    "from trino.dbapi import connect\n",
    "from trino.auth import BasicAuthentication\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize logging\n",
    "logfile = \"health_check\" + (datetime.now()).strftime(\"%Y_%m_%d_%H_%m_%s\") + \".log\"\n",
    "logging.basicConfig(filename=logfile, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# If either username or password are missing, exit the script without proceeding further\n",
    "if username.strip() == '' or password.strip() == '':\n",
    "    print(\"username / password cannot be empty. Please try again.\")\n",
    "    exit()\n",
    "\n",
    "# Load JSON configuration file\n",
    "with open(input_file) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    query_details = data\n",
    "\n",
    "# Define connection parameters\n",
    "conn = connect(\n",
    "    host=hostname,\n",
    "    port=port,\n",
    "    catalog=catalog,\n",
    "    verify=True,\n",
    "    schema=schema,\n",
    "    roles=role,\n",
    "    auth=BasicAuthentication(username, password),\n",
    "    http_headers={'Authorization': 'Bearer mytoken'}\n",
    ")\n",
    "\n",
    "# Create an empty dictionary to store query results\n",
    "query_results = {}\n",
    "\n",
    "# Function to fetch data with pagination\n",
    "def fetch_data_with_pagination(cursor, chunk_size=1000):\n",
    "    result_data = []\n",
    "    while True:\n",
    "        rows = cursor.fetchmany(chunk_size)\n",
    "        if not rows:\n",
    "            break\n",
    "        result_data.extend(rows)\n",
    "    return result_data\n",
    "\n",
    "for kpi, kpi_details in query_details.items():\n",
    "    for query_name, query_config in kpi_details.items():\n",
    "        query_text = query_config['query_text'].replace('analysis_start_date', analysis_start_date).replace('analysis_end_date', analysis_end_date)\n",
    "        \n",
    "        try:\n",
    "            cur = conn.cursor()\n",
    "            print('Executing the query for KPI - ', query_name, '..')\n",
    "            cur.execute(query_text)\n",
    "            result_data = fetch_data_with_pagination(cur)\n",
    "            result = pd.DataFrame(result_data, columns=[desc[0] for desc in cur.description])\n",
    "            if not result.empty:\n",
    "                query_results[query_name] = result\n",
    "                print('Done.')\n",
    "                logging.info(f\"Query '{query_name}' executed successfully. Result stored as DataFrame.\")\n",
    "            else:\n",
    "                print(f\"Error executing query '{query_name}': No data returned\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing query '{query_name}': {str(e)}\")\n",
    "        finally:\n",
    "            if cur:\n",
    "                cur.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aefdfca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8061/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2869df050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cluster metrics\n",
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.express as px\n",
    "import redis\n",
    "import json\n",
    "\n",
    "# Create DataFrames from query_results\n",
    "df1 = query_results['daily_cpu_metrics']\n",
    "df2 = query_results['hourly_cpu_metrics']\n",
    "df3 = query_results['daily_memory_metrics']\n",
    "df4 = query_results['hourly_memory_metrics']\n",
    "df5 = query_results['hourly_node_count']\n",
    "df6 = query_results['minutely_cpu_metrics']\n",
    "df7 = query_results['minutely_memory_metrics']\n",
    "df8 = query_results['minutely_node_count']\n",
    "\n",
    "# print(query_results['minutely_memory_metrics']['query_minute'].min())\n",
    "# print(query_results['minutely_memory_metrics']['query_minute'].max())\n",
    "\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"CPU / Memory Usage & Node Availability\"),\n",
    "    \n",
    "    # Dropdown filter for dataset selection\n",
    "    dcc.Dropdown(\n",
    "        id='dataset-selector',\n",
    "        options=[\n",
    "            {'label': 'Daily CPU Usage', 'value': 'df1'},\n",
    "            {'label': 'Hourly CPU Usage', 'value': 'df2'},\n",
    "            {'label': 'Daily Memory Usage', 'value': 'df3'},\n",
    "            {'label': 'Hourly Memory Usage', 'value': 'df4'},\n",
    "            {'label': 'Hourly Node Count', 'value': 'df5'},\n",
    "            {'label': 'Minutely CPU Usage', 'value': 'df6'},\n",
    "            {'label': 'Minutely Memory Usage', 'value': 'df7'},            \n",
    "            {'label': 'Minutely Node Count', 'value': 'df8'},            \n",
    "        ],\n",
    "        value='df6',  # Default selection\n",
    "    ),\n",
    "    \n",
    "    # Chart to display the selected dataset\n",
    "    dcc.Graph(id='line-chart', style={'width': '1000px', 'height': '500px'})\n",
    "\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected dataset\n",
    "@app.callback(\n",
    "    Output('line-chart', 'figure'),\n",
    "    Input('dataset-selector', 'value')\n",
    ")\n",
    "def update_chart(selected_dataset):\n",
    "    mapping = {\n",
    "        'df1': (df1, 'query_date', ['daily_median_sys_cpu', 'daily_median_proc_cpu'], 'Daily CPU Usage'),\n",
    "        'df2': (df2, 'query_date_hour', ['hourly_median_sys_cpu', 'hourly_median_proc_cpu'], 'Hourly CPU Usage'),\n",
    "        'df3': (df3, 'query_date', ['daily_median_qry_memory', 'daily_median_heap_memory'], 'Daily Memory Usage'),  # Adjust column names as necessary\n",
    "        'df4': (df4, 'query_date_hour', ['hourly_median_qry_memory', 'hourly_median_heap_memory'], 'Hourly Memory Usage'),\n",
    "        'df5': (df5, 'query_date_hour', ['hourly_median_node_count', 'hourly_avg_node_count'], 'Hourly Node Count'),\n",
    "        'df6': (df6, 'query_minute', ['minutely_median_sys_cpu', 'minutely_median_proc_cpu'], 'Minutely CPU Usage'),\n",
    "        'df7': (df7, 'query_minute', ['minutely_median_qry_memory', 'minutely_median_heap_memory'], 'Minutely Memory Usage'),\n",
    "        'df8': (df8, 'query_minute', ['minutely_node_count'], 'Minutely Node Count'),\n",
    "    }\n",
    "\n",
    "    df, x_col, y_cols, title = mapping[selected_dataset]\n",
    "    fig = px.line(df, x=x_col, y=y_cols, title=title)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=8061,debug=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c623610",
   "metadata": {},
   "source": [
    "# Query Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb39fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8062/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x281c286d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = query_results['query_trends']\n",
    "\n",
    "filtered_df = df\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Query Trends\"),\n",
    "    \n",
    "    # Dynamic multi-select slicer based on unique values in the 'query_type' column\n",
    "    dcc.Checklist(\n",
    "        id='query-type-slicer',\n",
    "        options=[\n",
    "            {'label': query_type, 'value': query_type}\n",
    "            for query_type in filtered_df['query_type'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=filtered_df['query_type'].unique().tolist(),  # Default selection (all unique values)\n",
    "    ),\n",
    "    \n",
    "    # Chart to display the sliced data\n",
    "    dcc.Graph(id='bar-chart'),\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected slicer values\n",
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    Input('query-type-slicer', 'value')\n",
    ")\n",
    "def update_chart(selected_query_types):\n",
    "    # Filter data by selected query types\n",
    "    filtered_df = df[df['query_type'].isin(selected_query_types)]\n",
    "    \n",
    "    # Group the data by 'query_date' and 'query_type' and aggregate the count of failed queries\n",
    "    grouped_df = filtered_df.groupby(['query_date', 'query_type'])['num_queries'].sum().reset_index()\n",
    "    \n",
    "    # Create the bar chart with 'query_date' on the x-axis, 'failed_queries_cnt' on the y-axis, and color by 'query_type'\n",
    "    fig = px.bar(grouped_df, x='query_date', y='num_queries', color='query_type',\n",
    "                 labels={'query_date': 'Query Date', 'num_queries': 'Query Count'},\n",
    "                 title='Query Count By Query Type')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(port=8062,debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4231dab",
   "metadata": {},
   "source": [
    "# Query Failure Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a837fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8063/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28bb1ee90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = query_results['query_failure_rate_by_query_type']\n",
    "\n",
    "filtered_df=df\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Query Failure Rate\"),\n",
    "    \n",
    "    # Dynamic multi-select slicer based on unique values in the 'query_type' column\n",
    "    dcc.Checklist(\n",
    "        id='query-type-slicer',\n",
    "        options=[\n",
    "            {'label': query_type, 'value': query_type}\n",
    "            for query_type in filtered_df['query_type'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=filtered_df['query_type'].unique().tolist(),  # Default selection (all unique values)\n",
    "    ),\n",
    "    \n",
    "    # Chart to display the sliced data\n",
    "    dcc.Graph(id='bar-chart'),\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected slicer values\n",
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    Input('query-type-slicer', 'value')\n",
    ")\n",
    "def update_chart(selected_query_types):\n",
    "    # Filter data by selected query types\n",
    "    filtered_df = df[df['query_type'].isin(selected_query_types)]\n",
    "    \n",
    "    # Group the data by 'query_date' and 'query_type' and aggregate the count of failed queries\n",
    "    grouped_df = filtered_df.groupby(['query_date', 'query_type'])['query_failure_rate'].sum().reset_index()\n",
    "    \n",
    "    # Create the bar chart with 'query_date' on the x-axis, 'failed_queries_cnt' on the y-axis, and color by 'query_type'\n",
    "    fig = px.bar(grouped_df, x='query_date', y='query_failure_rate', color='query_type',\n",
    "                 labels={'query_date': 'Query Date', 'query_failure_rate': 'Error Rate'},\n",
    "                 title='Query Failure Rate By Query Type')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8063)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f2ac8",
   "metadata": {},
   "source": [
    "# Failed queries by the query type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62551eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8064/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28ba01590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = query_results['query_failure_by_query_type']\n",
    "\n",
    "filtered_df=df\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Failed Queries Count By Query Type\"),\n",
    "    \n",
    "    # Dynamic multi-select slicer based on unique values in the 'query_type' column\n",
    "    dcc.Checklist(\n",
    "        id='query-type-slicer',\n",
    "        options=[\n",
    "            {'label': query_type, 'value': query_type}\n",
    "            for query_type in filtered_df['query_type'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=filtered_df['query_type'].unique().tolist(),  # Default selection (all unique values)\n",
    "    ),\n",
    "    \n",
    "    # Chart to display the sliced data\n",
    "    dcc.Graph(id='bar-chart'),\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected slicer values\n",
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    Input('query-type-slicer', 'value')\n",
    ")\n",
    "def update_chart(selected_query_types):\n",
    "    # Filter data by selected query types\n",
    "    filtered_df = df[df['query_type'].isin(selected_query_types)]\n",
    "    \n",
    "    # Group the data by 'query_date' and 'query_type' and aggregate the count of failed queries\n",
    "    grouped_df = filtered_df.groupby(['query_date', 'query_type'])['failed_queries_cnt'].sum().reset_index()\n",
    "    \n",
    "    # Create the bar chart with 'query_date' on the x-axis, 'failed_queries_cnt' on the y-axis, and color by 'query_type'\n",
    "    fig = px.bar(grouped_df, x='query_date', y='failed_queries_cnt', color='query_type',\n",
    "                 labels={'query_date': 'Query Date', 'failed_queries_cnt': 'Failed Queries Count'},\n",
    "                 title='')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8064)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813b180",
   "metadata": {},
   "source": [
    "# Failed queries by the error type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e36c95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8065/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28ef55550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = query_results['query_failure_by_error_type']\n",
    "\n",
    "filtered_df = df\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Failed Queries Count by Error Type\"),\n",
    "    \n",
    "    # Dynamic multi-select slicer based on unique values in the 'error_type' column\n",
    "    dcc.Checklist(\n",
    "        id='query-type-slicer',\n",
    "        options=[\n",
    "            {'label': error_type, 'value': error_type}\n",
    "            for error_type in filtered_df['error_type'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=filtered_df['error_type'].unique().tolist(),  # Default selection (all unique values)\n",
    "    ),\n",
    "    \n",
    "    # Chart to display the sliced data\n",
    "    dcc.Graph(id='bar-chart'),\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected slicer values\n",
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    Input('query-type-slicer', 'value')\n",
    ")\n",
    "def update_chart(selected_error_types):\n",
    "    # Filter data by selected query types\n",
    "    filtered_df = df[df['error_type'].isin(selected_error_types)]\n",
    "    \n",
    "    # Group the data by 'query_date' and 'error_type' and aggregate the count of failed queries\n",
    "    grouped_df = filtered_df.groupby(['query_date', 'error_type'])['failed_queries_cnt'].sum().reset_index()\n",
    "    \n",
    "    # Create the bar chart with 'query_date' on the x-axis, 'failed_queries_cnt' on the y-axis, and color by 'error_type'\n",
    "    fig = px.bar(grouped_df, x='query_date', y='failed_queries_cnt', color='error_type',\n",
    "                 labels={'query_date': 'Query Date', 'failed_queries_cnt': 'Failed Queries Count'},\n",
    "                 title='')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8065)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffdd356f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8066/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28b94e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = query_results['query_failure_by_error_type_and_name']\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Failed Queries Count By Error Type & Name\"),\n",
    "    \n",
    "    # First Dropdown for query type\n",
    "    dcc.Dropdown(\n",
    "        id='query-type-dropdown',\n",
    "        options=[\n",
    "            {'label': query_type, 'value': query_type}\n",
    "            for query_type in df['query_type'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=df['query_type'].unique(),  # Set the value to include all unique query types\n",
    "        multi=True,  # Allow multiple selections\n",
    "        placeholder=\"Select query type(s)\",\n",
    "    ),\n",
    "    \n",
    "    # Second Dropdown for error type\n",
    "    dcc.Dropdown(\n",
    "        id='error-type-dropdown',\n",
    "        options=[\n",
    "            {'label': error_type, 'value': error_type}\n",
    "            for error_type in df['error_type'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=df['error_type'].unique(),  # Set the value to include all unique error types\n",
    "        multi=True,  # Allow multiple selections\n",
    "        placeholder=\"Select error type(s)\",\n",
    "    ),\n",
    "\n",
    "    # Dynamic multi-select slicer based on unique values in the 'error_name' column\n",
    "    dcc.Checklist(\n",
    "        id='error-code-name-slicer',\n",
    "        options=[\n",
    "            {'label': error_name, 'value': error_name}\n",
    "            for error_name in df['error_code_name'].unique()  # Generate options dynamically\n",
    "        ],\n",
    "        value=df['error_code_name'].unique().tolist(),  # Default selection (all unique values)\n",
    "        style={'display': 'none'},  # Hide the checklist\n",
    "    ),\n",
    "\n",
    "    # Chart to display the sliced data\n",
    "    dcc.Graph(id='bar-chart'),\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected slicer values\n",
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    Input('error-code-name-slicer', 'value'),\n",
    "    Input('query-type-dropdown', 'value'),  # Added input for query-type-dropdown\n",
    "    Input('error-type-dropdown', 'value')  # Added input for error-type-dropdown\n",
    ")\n",
    "def update_chart(selected_error_names, selected_query_types, selected_error_types):\n",
    "    # Filter data by selected error types\n",
    "    filtered_df = df[df['error_code_name'].isin(selected_error_names)]\n",
    "    \n",
    "    # Filter data by selected query types\n",
    "    if selected_query_types:\n",
    "        filtered_df = filtered_df[filtered_df['query_type'].isin(selected_query_types)]\n",
    "    \n",
    "    # Filter data by selected error types\n",
    "    if selected_error_types:\n",
    "        filtered_df = filtered_df[filtered_df['error_type'].isin(selected_error_types)]\n",
    "\n",
    "    # Group the data by 'query_date' and 'error_name' and aggregate the count of failed queries\n",
    "    grouped_df = filtered_df.groupby(['query_date', 'error_code_name'])['failed_queries_cnt'].sum().reset_index()\n",
    "    \n",
    "    # Create the bar chart with 'query_date' on the x-axis, 'failed_queries_cnt' on the y-axis, and color by 'error_name'\n",
    "    fig = px.bar(grouped_df, x='query_date', y='failed_queries_cnt', color='error_code_name',\n",
    "                 labels={'query_date': 'Query Date', 'failed_queries_cnt': 'Failed Queries Count'},\n",
    "                 title='')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True,port=8066)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4f36e",
   "metadata": {},
   "source": [
    "Queries per minute, by query type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb5a1dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8067/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28b9da690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Assuming query_results is already populated\n",
    "df = query_results['queries_per_minute']\n",
    "\n",
    "# Convert 'query_date' to a date-time data type if it's not already\n",
    "df['query_date'] = pd.to_datetime(df['query_date'])\n",
    "\n",
    "# Define the dropdown options for query types\n",
    "query_type_options = [{'label': query_type, 'value': query_type} for query_type in df['query_type'].unique()]\n",
    "query_type_options.insert(0, {'label': 'ALL', 'value': 'ALL'})\n",
    "\n",
    "# Define the dropdown options for query dates\n",
    "query_date_options = [{'label': str(date), 'value': str(date)} for date in df['query_date'].dt.date.unique()]\n",
    "query_date_options.insert(0, {'label': 'ALL', 'value': 'ALL'})\n",
    "\n",
    "# Initialize the Dash app\n",
    "app1 = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app1.layout = html.Div([\n",
    "    html.H1(\"Queries per Minute\"),\n",
    "    \n",
    "    # Dropdown for selecting query types\n",
    "    dcc.Dropdown(\n",
    "        id='query-type-slicer-1',\n",
    "        options=query_type_options,\n",
    "        value=['ALL'],  # Default selection includes 'ALL'\n",
    "        multi=True,  # Allow multiple selections\n",
    "        clearable=True,  # Allow clearing selections\n",
    "        placeholder=\"Select query types\",  # Placeholder text\n",
    "    ),\n",
    "    \n",
    "    # Dropdown for selecting query dates\n",
    "    dcc.Dropdown(\n",
    "        id='query-date-slicer-1',\n",
    "        options=query_date_options,\n",
    "        value=['ALL'],  # Default selection includes 'ALL'\n",
    "        multi=True,  # Allow multiple selections\n",
    "        clearable=True,  # Allow clearing selections\n",
    "        placeholder=\"Select query dates\",  # Placeholder text\n",
    "    ),\n",
    "    \n",
    "    # Placeholder for the selected chart\n",
    "    dcc.Graph(id='selected-chart-1'),\n",
    "])\n",
    "\n",
    "# Define callback function to update the selected chart\n",
    "@app1.callback(\n",
    "    Output('selected-chart-1', 'figure'),\n",
    "    Input('query-type-slicer-1', 'value'),\n",
    "    Input('query-date-slicer-1', 'value')\n",
    ")\n",
    "def update_selected_chart(selected_query_types, selected_query_dates):\n",
    "    \n",
    "    # Filter the data frame based on selected query types\n",
    "    if 'ALL' in selected_query_types:\n",
    "        filtered_df = df  # Include all data if 'ALL' is selected\n",
    "    else:\n",
    "        filtered_df = df[df['query_type'].isin(selected_query_types)]\n",
    "    \n",
    "    # Further filter the data frame based on selected query dates\n",
    "    if 'ALL' not in selected_query_dates:\n",
    "        filtered_df = filtered_df[filtered_df['query_date'].dt.date.isin([pd.to_datetime(date).date() for date in selected_query_dates])]\n",
    "    \n",
    "    # Create a scatter plot for the selected data frame\n",
    "    selected_fig = px.scatter(filtered_df, x='query_date', y='query_minute', size='num_queries', color='num_queries', hover_name='num_queries')\n",
    "    \n",
    "    return selected_fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app1.run_server(debug=True, port=8067)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1eba24",
   "metadata": {},
   "source": [
    "Data Processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0a4cb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8068/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28ad176d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Assuming query_results is already populated\n",
    "df = query_results['data_processed']\n",
    "\n",
    "# Convert 'query_date' to a date-time data type\n",
    "df['query_date'] = pd.to_datetime(df['query_date'])\n",
    "\n",
    "# Create a list of KPIs to plot\n",
    "kpis = [\n",
    "    'avg_total_rows', 'avg_output_rows', 'avg_total_bytes',\n",
    "    'avg_output_bytes', 'avg_physical_input_bytes',\n",
    "    'avg_physical_input_rows', 'avg_completed_splits'\n",
    "]\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Data Processed Over Time\"),\n",
    "    \n",
    "    dcc.Dropdown(\n",
    "        id='kpi-selector',\n",
    "        options=[{'label': kpi, 'value': kpi} for kpi in kpis],\n",
    "        value=kpis[0],\n",
    "        multi=False\n",
    "    ),\n",
    "    \n",
    "    dcc.Graph(id='line-chart')\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected KPI\n",
    "@app.callback(\n",
    "    Output('line-chart', 'figure'),\n",
    "    Input('kpi-selector', 'value')\n",
    ")\n",
    "def update_chart(selected_kpi):\n",
    "    # Filter data for the selected KPI\n",
    "    fig = px.line(df, x='query_date', y=selected_kpi, \n",
    "                  labels={'query_date': 'Query Date', selected_kpi: selected_kpi},\n",
    "                  title=f'{selected_kpi}',\n",
    "                  template='plotly_dark')\n",
    "    \n",
    "    # Customize hover information\n",
    "    fig.update_traces(mode='lines+markers', hovertemplate=f'Query Date: %{{x}}<br>{selected_kpi}: %{{y}}<extra></extra>')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8068)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f48d3",
   "metadata": {},
   "source": [
    "Query Performance and time metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0934157d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8069/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28e409a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# Assuming query_results is already populated\n",
    "df = query_results['query_perf_and_time_metrics']\n",
    "\n",
    "# Convert 'query_date' to a date-time data type\n",
    "df['query_date'] = pd.to_datetime(df['query_date'])\n",
    "\n",
    "# Create a list of KPIs to plot\n",
    "kpis = [\n",
    "    'avg_cpu_time_secs', 'avg_wall_time_secs', 'avg_queued_time_secs',\n",
    "    'avg_resource_waiting_time_secs', 'avg_analysis_time_secs',\n",
    "    'avg_execution_time_secs', 'avg_planning_time_secs', 'avg_scheduled_time_secs'\n",
    "]\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Query Performance and Time Metrics\"),\n",
    "    \n",
    "    dcc.Dropdown(\n",
    "        id='kpi-selector',\n",
    "        options=[{'label': kpi, 'value': kpi} for kpi in kpis],\n",
    "        value=kpis[0],\n",
    "        multi=False\n",
    "    ),\n",
    "    \n",
    "    dcc.Graph(id='line-chart')\n",
    "])\n",
    "\n",
    "# Define a callback function to update the chart based on the selected KPI\n",
    "@app.callback(\n",
    "    Output('line-chart', 'figure'),\n",
    "    Input('kpi-selector', 'value')\n",
    ")\n",
    "def update_chart(selected_kpi):\n",
    "    # Filter data for the selected KPI\n",
    "    fig = px.line(df, x='query_date', y=selected_kpi, \n",
    "                  labels={'query_date': 'Query Date', selected_kpi: selected_kpi},\n",
    "                  title=f'{selected_kpi} Trend Over Time',\n",
    "                  template='plotly_dark')\n",
    "    \n",
    "    # Customize hover information\n",
    "    fig.update_traces(mode='lines+markers', hovertemplate=f'Query Date: %{{x}}<br>{selected_kpi}: %{{y}}<extra></extra>')\n",
    "    \n",
    "    # Set y-axis tick format to plain to avoid automatic unit conversion\n",
    "    fig.update_yaxes(tickformat=\"\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8069)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c12314",
   "metadata": {},
   "source": [
    "# Top X Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f633b2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8070/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28b6ca790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "max_display_chars = 50\n",
    "# Define a list of DataFrame keys and their corresponding labels\n",
    "data_frames = {\n",
    "    'top_x_data_scanned': 'Top X Data Scanned',\n",
    "    'top_x_splits_completed': 'Top X Completed splits',\n",
    "    'top_x_cpu_time': 'Top X CPU Time',\n",
    "    'top_x_execution_time': 'Top X Execution Time',\n",
    "    'top_x_scheduled_time': 'Top X Scheduled Time',\n",
    "    'top_x_analysis_time': 'Top X Analysis Time',\n",
    "    'top_x_planning_time': 'Top X Planning Time'\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Top X Data Analysis\"),\n",
    "    \n",
    "    # Dropdown for selecting the DataFrame\n",
    "    dcc.Dropdown(\n",
    "        id='data-frame-dropdown',\n",
    "        options=[{'label': label, 'value': key} for key, label in data_frames.items()],\n",
    "        value=list(data_frames.keys())[0],  # Default selection\n",
    "    ),\n",
    "    \n",
    "    # Dropdown for selecting query_date\n",
    "    dcc.Dropdown(\n",
    "        id='query-date-dropdown',\n",
    "        options=[],\n",
    "        multi=False,  # Allow only one selection\n",
    "        placeholder=\"Select query date\",\n",
    "    ),\n",
    "    \n",
    "    # Dropdown for selecting query_type\n",
    "    dcc.Dropdown(\n",
    "        id='query-type-dropdown',\n",
    "        options=[],\n",
    "        multi=False,  # Allow only one selection\n",
    "        placeholder=\"Select query type\",\n",
    "    ),\n",
    "    \n",
    "    # Table to display the filtered results\n",
    "    dcc.Loading(\n",
    "        id=\"loading-table\",\n",
    "        type=\"circle\",\n",
    "        children=[\n",
    "            html.Table(\n",
    "                id='query-results-table',\n",
    "                className='table',  # Apply CSS class for table styling\n",
    "                children=[\n",
    "                    html.Tr([html.Th(col) for col in []]),  # Empty headers initially\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "    \n",
    "    # Hidden div to store the selected query\n",
    "    html.Div(id='selected-query', style={'display': 'none'}),\n",
    "])\n",
    "\n",
    "# Define a callback function to populate the date and type dropdowns based on the selected DataFrame\n",
    "@app.callback(\n",
    "    Output('query-date-dropdown', 'options'),\n",
    "    Output('query-type-dropdown', 'options'),\n",
    "    Input('data-frame-dropdown', 'value')\n",
    ")\n",
    "def update_dropdown_options(selected_data_frame):\n",
    "    # Replace this with your actual data frames and columns\n",
    "    if selected_data_frame == 'top_x_data_scanned':\n",
    "        df = query_results['top_x_data_scanned']\n",
    "    if selected_data_frame == 'top_x_splits_completed':\n",
    "        df = query_results['top_x_splits_completed']        \n",
    "    elif selected_data_frame == 'top_x_planning_time':\n",
    "        df = query_results['top_x_planning_time']\n",
    "    elif selected_data_frame == 'top_x_cpu_time':\n",
    "        df = query_results['top_x_cpu_time']\n",
    "    elif selected_data_frame == 'top_x_execution_time':\n",
    "        df = query_results['top_x_execution_time']\n",
    "    elif selected_data_frame == 'top_x_scheduled_time':\n",
    "        df = query_results['top_x_scheduled_time']     \n",
    "    elif selected_data_frame == 'top_x_analysis_time':\n",
    "        df = query_results['top_x_analysis_time']     \n",
    "    elif selected_data_frame == 'top_x_queued_time':\n",
    "        df = query_results['top_x_queued_time']   \n",
    "    else:\n",
    "        # Handle unknown data frame key\n",
    "        df = query_results['top_x_planning_time']   \n",
    "#         df = pd.DataFrame()  # Empty DataFrame\n",
    "    \n",
    "    # Populate date and type dropdown options based on the selected DataFrame\n",
    "    date_options = [{'label': date, 'value': date} for date in df['query_date'].unique()]\n",
    "    type_options = [{'label': query_type, 'value': query_type} for query_type in df['query_type'].unique()]\n",
    "    \n",
    "    return date_options, type_options\n",
    "\n",
    "# Define a callback function to update the table and selected query\n",
    "@app.callback(\n",
    "    Output('query-results-table', 'children'),\n",
    "    Output('selected-query', 'children'),\n",
    "    Input('query-date-dropdown', 'value'),\n",
    "    Input('query-type-dropdown', 'value'),\n",
    "    Input('data-frame-dropdown', 'value')\n",
    ")\n",
    "def update_table_and_query(selected_date, selected_type, selected_data_frame):\n",
    "    if selected_data_frame == 'top_x_data_scanned':\n",
    "        df = query_results['top_x_data_scanned']\n",
    "    if selected_data_frame == 'top_x_splits_completed':\n",
    "        df = query_results['top_x_splits_completed']        \n",
    "    elif selected_data_frame == 'top_x_planning_time':\n",
    "        df = query_results['top_x_planning_time']\n",
    "    elif selected_data_frame == 'top_x_cpu_time':\n",
    "        df = query_results['top_x_cpu_time']\n",
    "    elif selected_data_frame == 'top_x_execution_time':\n",
    "        df = query_results['top_x_execution_time']\n",
    "    elif selected_data_frame == 'top_x_scheduled_time':\n",
    "        df = query_results['top_x_scheduled_time']     \n",
    "    elif selected_data_frame == 'top_x_analysis_time':\n",
    "        df = query_results['top_x_analysis_time']     \n",
    "    elif selected_data_frame == 'top_x_queued_time':\n",
    "        df = query_results['top_x_queued_time']   \n",
    "    else:\n",
    "        # Handle unknown data frame key\n",
    "        df = query_results['top_x_data_scanned']   \n",
    "#         df = pd.DataFrame()  # Empty DataFrame\n",
    "    \n",
    "    # Filter the DataFrame based on selected date and type\n",
    "    filtered_df = df \n",
    "    # filtered_df = df.drop(columns=['query'])\n",
    "    if selected_date:\n",
    "        filtered_df = filtered_df[filtered_df['query_date'] == selected_date]\n",
    "    if selected_type:\n",
    "        filtered_df = filtered_df[filtered_df['query_type'] == selected_type]\n",
    "    \n",
    "#     Generate the HTML table with borders and truncated query column\n",
    "    \n",
    "    table = html.Table(\n",
    "        [\n",
    "            html.Tr([html.Th(col) for col in df.columns]),\n",
    "            *[html.Tr([\n",
    "                html.Td(\n",
    "                    filtered_df.iloc[i]['query'][:max_display_chars] + (\n",
    "                        '...' if len(filtered_df.iloc[i]['query']) > max_display_chars else ''), \n",
    "                    title=filtered_df.iloc[i]['query'],  # Full query for tooltip\n",
    "                    className='tooltip', \n",
    "                    **{'data-tooltip': filtered_df.iloc[i]['query']}\n",
    "                ) if col == 'query' else html.Td(filtered_df.iloc[i][col]) \n",
    "                for col in df.columns\n",
    "            ]) for i in range(len(filtered_df))],\n",
    "        ],\n",
    "        className='table-bordered',  # Apply CSS class for table borders\n",
    "    )\n",
    "  \n",
    "    # Determine the selected query text (if any)\n",
    "    selected_query = None\n",
    "    if dash.callback_context.triggered:\n",
    "        trigger_id = dash.callback_context.triggered[0]['prop_id'].split('.')[0]\n",
    "        if trigger_id == 'query-results-table':\n",
    "            selected_query = filtered_df.iloc[dash.callback_context.triggered[0]['row_id']]['query']\n",
    "    \n",
    "    return table, selected_query\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa1fd1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
